#!/usr/bin/env cram
# vim: set syntax=cram :

Cram (http://pypi.python.org/pypi/cram) tests for bloscpack

Run with coverage.

  $ if [ -n "$COVERAGE" ]; then
  >   alias blpk="COVERAGE_FILE=$TESTDIR/.coverage `which coverage` run --timid -a $TESTDIR/blpk"
  > else
  >   alias blpk="$TESTDIR/blpk"
  > fi

In case of no arguments, show a usage message:

  $ blpk
  usage: blpk [-h] [--version] [-v | -d] [-f] [-n [1, 256]]  ...
  blpk: error: too few arguments
  [2]

Help for global options and subcommands:

  $ blpk --help
  usage: blpk [-h] [--version] [-v | -d] [-f] [-n [1, 256]]  ...
  
  command line de/compression with blosc
  
  optional arguments:
    -h, --help            show this help message and exit
    --version             show program's version number and exit
    -v, --verbose         be verbose about actions
    -d, --debug           print debugging output too
  
  global options:
    -f, --force           disable overwrite checks for existing files
                          (use with caution)
    -n [1, 256], --nthreads [1, 256]
                          set number of threads, (default: * (ncores)) (glob)
  
  subcommands:
    
      compress            perform compression on file
      c                   alias for 'compress'
      decompress          perform decompression on file
      d                   alias for 'decompress'
      append              append data to a compressed file
      a                   alias for 'append'
      info                print information about a compressed file
      i                   alias for 'info'

Help for the subcommands:

  $ blpk compress --help
  usage: blpk compress [-h] [-t <size>] [-l [0, 9]] [-s] [-c <codec>]
                       [-z <size>] [-k <checksum>] [-o] [-m <metadata>]
                       <in_file> [<out_file>]
  
  positional arguments:
    <in_file>             file to be compressed
    <out_file>            file to compress to
  
  optional arguments:
    -h, --help            show this help message and exit
    -z <size>, --chunk-size <size>
                          set desired chunk size or 'max' (default: 1M)
  
  blosc settings:
    -t <size>, --typesize <size>
                          typesize for blosc (default: 8)
    -l [0, 9], --clevel [0, 9]
                          compression level (default: 7)
    -s, --no-shuffle      deactivate shuffle
    -c <codec>, --codec <codec>
                          codec to be used by Blosc: 
                          blosclz, lz4, lz4hc, snappy, zlib
                           (default: blosclz)
  
  bloscpack settings:
    -k <checksum>, --checksum <checksum>
                          set desired checksum:
                          None, adler32, crc32
                          md5, sha1, sha224
                          sha256, sha384, sha512
                           (default: adler32)
    -o, --no-offsets      deactivate offsets
    -m <metadata>, --metadata <metadata>
                          file containing the metadata, must contain valid JSON
  $ blpk decompress --help
  usage: blpk decompress [-h] [-e] <in_file> [<out_file>]
  
  positional arguments:
    <in_file>             file to be decompressed
    <out_file>            file to decompress to
  
  optional arguments:
    -h, --help            show this help message and exit
    -e, --no-check-extension
                          disable checking input file for extension (*.blp)
                          (requires use of <out_file>)
  $ blpk append --help
  usage: blpk append [-h] [-t <size>] [-l [0, 9]] [-s] [-c <codec>] [-e]
                     [-m <metadata>]
                     <original_file> <new_file>
  
  positional arguments:
    <original_file>       file to append to
    <new_file>            file to append from
  
  optional arguments:
    -h, --help            show this help message and exit
    -e, --no-check-extension
                          disable checking original file for extension (*.blp)
    -m <metadata>, --metadata <metadata>
                          file containing the metadata, must contain valid JSON
  
  blosc settings:
    -t <size>, --typesize <size>
                          typesize for blosc (default: 8)
    -l [0, 9], --clevel [0, 9]
                          compression level (default: 7)
    -s, --no-shuffle      deactivate shuffle
    -c <codec>, --codec <codec>
                          codec to be used by Blosc: 
                          blosclz, lz4, lz4hc, snappy, zlib
                           (default: blosclz)

  $ blpk info --help
  usage: blpk info [-h] <file>
  
  positional arguments:
    <file>      file to show info for
  
  optional arguments:
    -h, --help  show this help message and exit

Check the version output is sane.

  $ blpk --version
  bloscpack: '.*' python-blosc: '.*' blosc: '.*' (re)

Create a test datafile.

  $ python -c "import numpy; a = numpy.linspace(0, 100, 2e7); f = open('data.dat', 'w');  f.write(a.tostring()) "
  $ ls data.dat
  data.dat
  $ echo '{"dtype": "float64", "shape": [20000000], "container": "numpy"}' > meta.json
  $ ls meta.json
  meta.json

Basic compression:

  $ blpk compress data.dat
  $ ls data.dat.blp
  data.dat.blp
  $ rm data.dat.blp
  $ blpk c data.dat
  $ ls data.dat.blp
  data.dat.blp
  $ rm data.dat.blp

Compression to a file:

  $ blpk compress data.dat packed.blp
  $ ls packed.blp
  packed.blp
  $ rm packed.blp

Compression with different chunksizes:

  $ blpk compress --chunk-size 64K data.dat
  $ ls data.dat.blp
  data.dat.blp
  $ rm data.dat.blp

  $ blpk compress --chunk-size 65536 data.dat
  $ ls data.dat.blp
  data.dat.blp
  $ rm data.dat.blp

  $ blpk compress --chunk-size max data.dat
  $ ls data.dat.blp
  data.dat.blp
  $ rm data.dat.blp

  $ blpk compress --chunk-size -1 data.dat
  blpk: error: --chunk-size must be > 0 
  [1]

  $ blpk compress --chunk-size NO_SUCH_VALUE data.dat
  blpk: error: --chunk-size error: invalid literal for int() with base 10: 'NO_SUCH_VALUE' or 'max'
  [1]

Basic decompression:

  $ blpk compress data.dat
  $ rm data.dat
  $ blpk decompress data.dat.blp
  $ ls data.dat
  data.dat
  $ rm data.dat.blp
  $ blpk compress data.dat
  $ rm data.dat
  $ blpk d data.dat.blp
  $ rm data.dat.blp
  $ ls data.dat
  data.dat

Decompression to a file:

  $ blpk compress data.dat
  $ blpk decompress data.dat.blp data.dat.dcmp
  $ ls data.dat.dcmp
  data.dat.dcmp
  $ rm data.dat.dcmp

Use the force, Luke:

  $ blpk compress data.dat
  blpk: error: output file 'data.dat.blp' exists!
  [1]
  $ blpk --force compress data.dat
  $ blpk d data.dat.blp
  blpk: error: output file 'data.dat' exists!
  [1]
  $ blpk --force decompress data.dat.blp

Get some info on the file:

  $ blpk info data.dat.blp
  blpk: bloscpack header: 
  blpk:     format_version=3,
  blpk:     offsets=True,
  blpk:     metadata=False,
  blpk:     checksum='adler32',
  blpk:     typesize=8,
  blpk:     chunk_size=1.0M (1048576B),
  blpk:     last_chunk=602.0K (616448B),
  blpk:     nchunks=153,
  blpk:     max_app_chunks=1530
  blpk: 'offsets':
  blpk: [13496,168668,310991,471593,628230,...]
  $ blpk i data.dat.blp
  blpk: bloscpack header: 
  blpk:     format_version=3,
  blpk:     offsets=True,
  blpk:     metadata=False,
  blpk:     checksum='adler32',
  blpk:     typesize=8,
  blpk:     chunk_size=1.0M (1048576B),
  blpk:     last_chunk=602.0K (616448B),
  blpk:     nchunks=153,
  blpk:     max_app_chunks=1530
  blpk: 'offsets':
  blpk: [13496,168668,310991,471593,628230,...]
  $ rm data.dat.blp
  $ blpk info data.dat.blp
  blpk: error: file 'data.dat.blp' does not exist!
  [1]
  $ blpk i data.dat
  blpk: error: the magic marker 'blpk' is missing from the bloscpack header, instead we found: '\x00\x00\x00\x00'
  blpk: error: This might not be a bloscpack compressed file.
  [1]

Try using no offsets:

  $ blpk compress --no-offsets data.dat
  $ blpk info data.dat.blp
  blpk: bloscpack header: 
  blpk:     format_version=3,
  blpk:     offsets=False,
  blpk:     metadata=False,
  blpk:     checksum='adler32',
  blpk:     typesize=8,
  blpk:     chunk_size=1.0M (1048576B),
  blpk:     last_chunk=602.0K (616448B),
  blpk:     nchunks=153,
  blpk:     max_app_chunks=0
  $ rm data.dat.blp

Try using alternative checksum:

  $ blpk compress --checksum sha512 data.dat
  $ blpk info data.dat.blp
  blpk: bloscpack header: 
  blpk:     format_version=3,
  blpk:     offsets=True,
  blpk:     metadata=False,
  blpk:     checksum='sha512',
  blpk:     typesize=8,
  blpk:     chunk_size=1.0M (1048576B),
  blpk:     last_chunk=602.0K (616448B),
  blpk:     nchunks=153,
  blpk:     max_app_chunks=1530
  blpk: 'offsets':
  blpk: [13496,168728,311111,471773,628470,...]
  $ rm data.dat.blp

Try using an alternative codec ('lz4' should be available):

  $ blpk compress --codec lz4 data.dat
  $ blpk info data.dat.blp
  blpk: bloscpack header: 
  blpk:     format_version=3,
  blpk:     offsets=True,
  blpk:     metadata=False,
  blpk:     checksum='adler32',
  blpk:     typesize=8,
  blpk:     chunk_size=1.0M (1048576B),
  blpk:     last_chunk=602.0K (616448B),
  blpk:     nchunks=153,
  blpk:     max_app_chunks=1530
  blpk: 'offsets':
  blpk: [13496,173720,305178,438821,571575,...]
  $ rm data.dat.blp

Try using an  codec that is not available:

  $ blpk compress --codec NO_SUCH_CODEC data.dat
  usage: blpk compress [-h] [-t <size>] [-l [0, 9]] [-s] [-c <codec>]
                       [-z <size>] [-k <checksum>] [-o] [-m <metadata>]
                       <in_file> [<out_file>]
  blpk compress: error: argument -c/--codec: invalid choice: 'NO_SUCH_CODEC' (choose from 'blosclz', 'lz4', 'lz4hc', 'snappy', 'zlib')
  [2]

Get more information using --verbose:

  $ blpk --verbose compress data.dat
  blpk: using [0-9]+ threads (re)
  blpk: getting ready for compression
  blpk: input file is: 'data.dat'
  blpk: output file is: 'data.dat.blp'
  blpk: input file size: 152.59M (160000000B)
  blpk: nchunks: 153
  blpk: chunk_size: 1.0M (1048576B)
  blpk: output file size: 16.2M (16984384B)
  blpk: compression ratio: 0.106152
  blpk: done
  $ rm data.dat.blp

Add metadata to the file:

  $ blpk compress --metadata meta.json data.dat
  $ blpk info data.dat.blp
  blpk: bloscpack header: 
  blpk:     format_version=3,
  blpk:     offsets=True,
  blpk:     metadata=True,
  blpk:     checksum='adler32',
  blpk:     typesize=8,
  blpk:     chunk_size=1.0M (1048576B),
  blpk:     last_chunk=602.0K (616448B),
  blpk:     nchunks=153,
  blpk:     max_app_chunks=1530
  blpk: 'metadata':
  blpk: {   u'container': u'numpy', u'dtype': u'float64', u'shape': [20000000]}
  blpk: 'metadata_header':
  blpk: {   'magic_format': 'JSON',
  blpk:     'max_meta_size': 580,
  blpk:     'meta_checksum': 'adler32',
  blpk:     'meta_codec': 'zlib',
  blpk:     'meta_comp_size': 58,
  blpk:     'meta_level': 6,
  blpk:     'meta_options': '00000000',
  blpk:     'meta_size': 58,
  blpk:     'user_codec': ''}
  blpk: 'offsets':
  blpk: [14112,169284,311607,472209,628846,...]
  $ blpk decompress data.dat.blp data.dat.dcmp
  blpk: Metadata is:
  blpk: '{u'dtype': u'float64', u'shape': [20000000], u'container': u'numpy'}'

Test basic append:


  $ ls -lah  data.dat.blp
  .* 1 .* .* 17M .* .* .* data.dat.blp (re)
  $ blpk append data.dat.blp data.dat
  $ ls -lah  data.dat.blp
  .* 1 .* .* 33M .* .* .* data.dat.blp (re)

Use an invalid number of threads:

  $ blpk -n 257
  blpk: error: -n must be 1 <= n <= 256
  [1]
